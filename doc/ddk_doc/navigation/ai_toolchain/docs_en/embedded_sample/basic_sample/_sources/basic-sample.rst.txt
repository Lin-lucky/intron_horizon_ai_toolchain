Foreword
==========

The Basic Sample Package (hereafter as the BSP) is composed by samples in 3 categories:

1. ``dnn`` API know-how samples.
2. Demonstrations of special features, e.g. custom OP etc.
3. Miscellaneous samples of Non-NV12 input model.

The BSP makes it easy for developers to build their own applications.

Introduction of Release Package
===================================

​The BSP's release package consists of the following:

.. table::

  +------------------------+------------------------------------+
  | RELEASE PACKAGE        | DESCRIPTIONS                       |
  +------------------------+------------------------------------+
  | horizon_runtime_sample | including sample code and scripts. |
  +------------------------+------------------------------------+

Sample Code Package
---------------------

​Directory of the BSP is shown as below:

.. code-block:: bash

  +---horizon_runtime_sample
    ├── code                        # source code of samples
    │   ├── 00_quick_start          # a quick-start single image inference sample using the MobileNetv1 model
    │   │   ├── CMakeLists.txt
    │   │   └── src
    │   ├── 01_api_tutorial         # dnn API sample code
    │   │   ├── CMakeLists.txt
    │   │   ├── mem
    │   │   ├── model
    │   │   ├── resize
    │   │   └── tensor
    │   ├── 02_advanced_samples     # special feature sample
    │   │   ├── CMakeLists.txt
    │   │   ├── custom_identity
    │   │   └── multi_model_batch
    │   ├── 03_misc                 # miscellaneous samples
    │   │   ├── CMakeLists.txt
    │   │   ├── lenet_gray
    │   │   └── resnet_feature
    │   ├── build_xj3.sh             # compilation script
    │   ├── CMakeLists.txt
    │   └── deps                    # compilation dependencies
    │       └── aarch64
    ├── xj3
    │   ├── data                    # preset data
    │   │   ├── cls_images
    │   │   ├── det_images
    │   │   ├── misc_data
    │   ├── model
    │   │   └── README.md
    │   └── script                  # scripts to run samples
    │       ├── 00_quick_start
    │       ├── 01_api_tutorial
    │       ├── 02_advanced_samples
    │       ├── 03_misc
    │       ├── aarch64             # compilation generated executables and dependencies
    │       └── README.md
    └── README.md


- The **00_quick_start** folder contains a quick-start sample based on the ``dnn`` API. 
  This script inference a single image and parse the results using MobileNetv1.
- The **01_api_tutorial** folder contains API teaching code, including 4 parts: 
  **mem**, **model**, **resize** and **tensor**.
- The **02_advanced_samples** folder contains the sample that demonstrates the custom operator (CustomIdentity) feature.
- The **03_misc** folder contains those miscellaneous samples of non-NV12 input models.
- The **xj3/** folder contains scripts to run samples, preset data and related models.
- The build_xj3.sh is a quick application compilation script.
- The **deps** folder contains those sample code required third party dependencies. 
  Users can replace or delete depending on their own needs.
- The **tools** folder contains the ``hrt_bin_dump`` and ``hrt_model_exec`` tools.

Prerequisites
==========================

Prepare the Dev Board
--------------------------------

1. Upgrade the system image to the BSP recommended version according to the upgrade instructions.

2. Ensure the connection between local dev machine and the dev board.

Compilation
-------------------------

​Install the gcc-linaro-6.5.0-2018.12-x86_64_aarch64-linux-gnu cross-compilation tool 
and perform the build_xj3.sh script in the **horizon_runtime_sample/code** folder to compile executable programs 
in real machine environment. The executable program and corresponding dependencies will be copied into the 
**aarch64** sub-folder in the **xj3/script** folder. 

.. note::

  The default location of the cross-compilation tool specified by the build_xj3.sh script 
  is in the **/opt** sub-folder, if you wish to change the location, 
  please modify the build_xj3.sh script.

.. code-block:: shell

  export CC=/opt/gcc-linaro-6.5.0-2018.12-x86_64_aarch64-linux-gnu/bin/aarch64-linux-gnu-gcc
  export CXX=/opt/gcc-linaro-6.5.0-2018.12-x86_64_aarch64-linux-gnu/bin/aarch64-linux-gnu-g++

How to Use
============

Basic Samples
-----------------

Sample scripts are in the **xj3/script** folder, the directory structure after compilation is as follows:

.. code-block:: shell

  script:
  ├── 00_quick_start
  │   ├── README.md
  │   └── run_mobilenetV1.sh
  ├── 01_api_tutorial
  │   ├── model.sh
  │   ├── README.md
  │   ├── resize_bgr.sh
  │   ├── resize_y.sh
  │   ├── sys_mem.sh
  │   └── tensor.sh
  ├── 02_advanced_samples
  │   ├── custom_arm_op_custom_identity.sh
  │   ├── README.md
  │   └── run_multi_model_batch.sh
  ├── 03_misc
  │   ├── README.md
  │   ├── run_lenet.sh
  │   └── run_resnet50_feature.sh
  ├── aarch64                                    # compilation generated executables and dependencies
  │   ├── bin
  │   │   ├── model_example
  │   │   ├── resize_bgr_example
  │   │   ├── resize_y_example
  │   │   ├── run_custom_op
  │   │   ├── run_lenet_gray
  │   │   ├── run_mobileNetV1_224x224
  │   │   ├── run_multi_model_batch  
  │   │   ├── run_resnet_feature
  │   │   ├── sys_mem_example
  │   │   └── tensor_example
  │   └── lib
  │       ├── libdnn.so
  │       ├── libhbrt_bernoulli_aarch64.so
  │       └── libopencv_world.so.3.4
  └── README.md

quick_start
~~~~~~~~~~~~~~~~~~~~

Refers to the quickstart sample in the **00_quick_start** directory.

.. code-block:: shell

  00_quick_start/
  ├── README.md
  └── run_mobilenetV1.sh

- the run_mobilenetV1.sh script implements single-image inference sample using the MobileNetv1 model.

API Tutorial
~~~~~~~~~~~~~~~~

​The API tutorial refers to the samples in the **01_api_tutorial** folder. 
These samples help developers understand how to use the embedded APIs.
This folder contains the following scripts:

.. code-block:: shell

  ├── model.sh
  ├── resize_bgr.sh
  ├── resize_y.sh
  ├── sys_mem.sh
  └── tensor.sh

- The model.sh script reads model information. 
  To run it, enter the **01_api_tutorial** and perform ``sh model.sh``. 
  See below code block:

  .. code-block:: shell

    #!/bin/sh

    root@j3dvbj3-hynix2G-3200:/userdata/ruxin.song/xj3/script/01_api_tutorial# sh model.sh
    ../aarch64/bin/model_example --model_file_list=../../model/runtime/mobilenetv1/mobilenetv1_nv12_hybrid_horizonrt.bin
    I0000 00:00:00.000000 24638 vlog_is_on.cc:197] RAW: Set VLOG level for "*" to 3
    [HBRT] set log level as 0. version = 3.12.1
    [BPU_PLAT]BPU Platform Version(1.2.2)!
    [HorizonRT] The model builder version = 1.3.3
    I0108 04:19:27.245879 24638 model_example.cc:104] model count:1, model[0]: mobilenetv1_nv12
    I0108 04:19:27.246064 24638 model_example.cc:112] hbDNNGetModelHandle [mobilenetv1_nv12] success!
    I0108 04:19:27.246139 24638 model_example.cc:189] [mobilenetv1_nv12] Model Info:  input num: 1, input[0] validShape: ( 1, 3, 224, 224 ), alignedShape: ( 1, 4, 224, 224 ), tensorLayout: 2, tensorType: 1, output num: 1, output[0] validShape: ( 1, 1000, 1, 1 ), alignedShape: ( 1, 1000, 1, 1 ), tensorLayout: 2, tensorType: 13

- The resize_bgr.sh script helps understand how to use the ``hbDNNResize`` API. 
  It crops the part of an 1352x900 image whose coordinates equal [5，19，340，343], resizes it into 402x416 and saves it.
  To run it. enter the **01_api_tutorial** and perform ``sh resize_bgr.sh``. 
  See below code block:

  .. code-block:: shell

    #!/bin/sh

    root@j3dvbj3-hynix2G-3200:/userdata/ruxin.song/xj3/script/01_api_tutorial# sh resize_bgr.sh
    ../aarch64/bin/resize_bgr_example --image_file=../../data/det_images/kite.jpg --resize_height=416 --resize_width=402 --resized_image=./resize_bgr.jpg --crop_x1=5 --crop_x2=340 --crop_y1=19 --crop_y2=343
    I0000 00:00:00.000000 24975 vlog_is_on.cc:197] RAW: Set VLOG level for "*" to 3
    I0108 06:58:03.327212 24975 resize_bgr_example.cc:116] Original shape: 1352x900 ,dest shape:402x416 ,aligned shape:402x416
    [HBRT] set log level as 0. version = 3.12.1
    [BPU_PLAT]BPU Platform Version(1.2.2)!
    I0108 06:58:03.328739 24975 resize_bgr_example.cc:139] resize success!
    I0108 06:58:03.335835 24975 resize_bgr_example.cc:143] wait task done finished!

After successful execution, an image named resize_bgr.jpg should be saved into the current path.

- The resize_y.sh script helps understand how to use the ``hbDNNResize`` API. 
  It resizes an image into 416x402. To run it, enter the  **01_api_tutorial** folder and perform  ``sh resize_y.sh``. 
  See below code block:

  .. code-block:: shell

    #!/bin/sh

    root@j3dvbj3-hynix2G-3200:/userdata/ruxin.song/xj3/script/01_api_tutorial# sh resize_y.sh
    ../aarch64/bin/resize_y_example --image_file=../../data/det_images/kite.jpg --resize_height=416 --resize_width=402 --resized_image=./resize_y.jpg
    I0000 00:00:00.000000 24992 vlog_is_on.cc:197] RAW: Set VLOG level for "*" to 3
    I0108 06:59:36.887241 24992 resize_y_example.cc:101] Original shape: 1352x900 ,dest shape:402x416 ,aligned shape:402x416
    [HBRT] set log level as 0. version = 3.12.1
    [BPU_PLAT]BPU Platform Version(1.2.2)!
    I0108 06:59:36.888770 24992 resize_y_example.cc:119] resize success
    I0108 06:59:36.891711 24992 resize_y_example.cc:123] wait resize success
    I0108 06:59:36.891798 24992 resize_y_example.cc:129] spent time: 0.003463

After successful execution, an image named resize_y.jpg should be saved into the current path.

- The sys_mem.sh script helps understand how to use the ``hbSysAllocMem``, ``hbSysFlushMem`` and ``hbSysFreeMem`` APIs. 
  To run it, enter the **01_api_tutorial** folder and perform ``sh sys_mem.sh``.

- The tensor.sh script helps understand how to prepare model input and output tensors. 
  To run it, enter the **01_api_tutorial** folder and perform ``sh tensor.sh``.
  See below code block:

  .. code-block:: shell

    root@j3dvbj3-hynix2G-3200:/userdata/ruxin.song/xj3/script/01_api_tutorial# sh tensor.sh
    Tensor data type:0, Tensor layout: 2, shape:1x1x721x1836, aligned shape:1x1x721x1840
    Tensor data type:1, Tensor layout: 2, shape:1x3x773x329, aligned shape:1x3x773x336
    Tensor data type:2, Tensor layout: 2, shape:1x3x108x1297, aligned shape:1x3x108x1312
    Tensor data type:5, Tensor layout: 2, shape:1x3x858x477, aligned shape:1x3x858x477
    Tensor data type:5, Tensor layout: 0, shape:1x920x102x3, aligned shape:1x920x102x3
    Tensor data type:4, Tensor layout: 2, shape:1x3x723x1486, aligned shape:1x3x723x1486
    Tensor data type:4, Tensor layout: 0, shape:1x372x366x3, aligned shape:1x372x366x3
    Tensor data type:3, Tensor layout: 2, shape:1x3x886x291, aligned shape:1x3x886x291
    Tensor data type:3, Tensor layout: 0, shape:1x613x507x3, aligned shape:1x613x507x3

Advanced Samples
~~~~~~~~~~~~~~~~~~~~~

The advanced samples refers to those samples in the **02_advanced_samples** folder 
and they are used for demonstrating how to use the custom OP special feature. 
The folder contains below scripts:

.. code-block:: shell

  ├── custom_arm_op_custom_identity.sh
  └── run_multi_model_batch.sh

- The custom_arm_op_custom_identity.sh script implement model inference using user customized operator. 
  To run it, enter the **02_advanced_samples** folder and perform ``sh custom_arm_op_custom_identity.sh``.
  See below code block:

  .. code-block:: shell

    root@j3dvbj3-hynix2G-3200:/userdata/ruxin.song/xj3/script/02_advanced_samples# sh custom_arm_op_custom_identity.sh
    ../aarch64/bin/run_custom_op --model_file=../../model/runtime/googlenet_cop/googlenet_cop_224x224_nv12.bin --image_file=../../data/cls_images/zebra_cls.jpg --image_height=224 --image_width=224 --top_k=5
    I0000 00:00:00.000000 25036 vlog_is_on.cc:197] RAW: Set VLOG level for "*" to 3
    I0108 07:04:16.743277 25036 main.cpp:138] hbDNNRegisterLayerCreator success
    [HBRT] set log level as 0. version = 3.12.1
    [BPU_PLAT]BPU Platform Version(1.2.2)!
    [HorizonRT] The model builder version = 1.3.4
    I0108 07:04:16.902737 25036 main.cpp:153] hbDNNGetModelNameList success
    I0108 07:04:16.902809 25036 main.cpp:160] hbDNNGetModelHandle success
    I0108 07:04:16.920487 25036 main.cpp:169] read image to nv12 success
    I0108 07:04:16.920793 25036 main.cpp:179] prepare nv12 tensor success
    I0108 07:04:16.920900 25036 main.cpp:189] prepare tensor success
    I0108 07:04:16.922179 25036 main.cpp:200] hbDNNInfer success
    I0108 07:04:16.996123 25036 main.cpp:205] task done
    I0108 07:04:16.996308 25036 main.cpp:210] task post process success
    I0108 07:04:16.996355 25036 main.cpp:217] TOP 0 result id: 340
    I0108 07:04:16.996380 25036 main.cpp:217] TOP 1 result id: 351
    I0108 07:04:16.996403 25036 main.cpp:217] TOP 2 result id: 83
    I0108 07:04:16.996426 25036 main.cpp:217] TOP 3 result id: 352
    I0108 07:04:16.996448 25036 main.cpp:217] TOP 4 result id: 353

- The run_multi_model_batch.sh script implements the feature of inferencing multiple small models by the batch. 
  Enter the **02_advanced_samples** directory and run ``sh run_multi_model_batch.sh`` command as shown in below code block: 

  .. code-block:: shell
  
    root@x3sdbx3-hynix2G-3200:/userdata/chaoliang/xj3/script/02_advanced_samples# sh run_multi_model_batch.sh
    ../aarch64/bin/run_multi_model_batch --model_file=../../model/runtime/googlenet/googlenet_224x224_nv12.bin,../../model/runtime/mobilenetv2/mobilenetv2_224x224_nv12.bin --input_file=../../data/cls_images/zebra_cls.jpg,../../data/cls_images/zebra_cls.jpg
    I0000 00:00:00.000000 17060 vlog_is_on.cc:197] RAW: Set VLOG level for "*" to 3
    [HBRT] set log level as 0. version = 3.13.4
    [BPU_PLAT]BPU Platform Version(1.1.1)!
    [HorizonRT] The model builder version = 1.3.18
    [HorizonRT] The model builder version = 1.3.18
    I0317 12:37:18.249785 17060 main.cpp:119] hbDNNInitializeFromFiles success
    I0317 12:37:18.250029 17060 main.cpp:127] hbDNNGetModelNameList success
    I0317 12:37:18.250071 17060 main.cpp:141] hbDNNGetModelHandle success
    I0317 12:37:18.283633 17060 main.cpp:155] read image to nv12 success
    I0317 12:37:18.284270 17060 main.cpp:172] prepare input tensor success
    I0317 12:37:18.284456 17060 main.cpp:184] prepare output tensor success
    I0317 12:37:18.285344 17060 main.cpp:218] infer success
    I0317 12:37:18.296559 17060 main.cpp:223] task done
    I0317 12:37:18.296701 17060 main.cpp:228] googlenet class result id: 340
    I0317 12:37:18.296805 17060 main.cpp:232] mobilenetv2 class result id: 340
    I0317 12:37:18.296887 17060 main.cpp:236] release task success

Miscellaneous Samples
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The miscellaneous samples refers to the sample in the **03_misc** folder. 
They are used for demonstrating how to use the non-NV12 input models. 
It contains below scripts:

.. code-block:: shell

  ├── run_lenet.sh
  └── run_resnet50_feature.sh

- The run_lenet.sh is used for implementing Lenet model inference using Y data input. 
  To run it, enter the **03_misc** folder and perform ``sh run_lenet.sh`` . 
  See below code block:

  .. code-block:: shell

    root@j3dvbj3-hynix2G-3200:/userdata/ruxin.song/xj3/script/03_misc# sh run_lenet.sh
    ../aarch64/bin/run_lenet_gray --model_file=../../model/runtime/lenet_gray/lenet_gray_hybrid_horizonrt.bin --data_file=../../data/misc_data/7.bin --image_height=28 --image_width=28 --top_k=5
    I0000 00:00:00.000000 25139 vlog_is_on.cc:197] RAW: Set VLOG level for "*" to 3
    [HBRT] set log level as 0. version = 3.12.1
    [BPU_PLAT]BPU Platform Version(1.2.2)!
    [HorizonRT] The model builder version = 1.3.3
    I0108 07:23:35.507514 25139 run_lenet_gray.cc:145] hbDNNInitializeFromFiles success
    I0108 07:23:35.507737 25139 run_lenet_gray.cc:153] hbDNNGetModelNameList success
    I0108 07:23:35.507771 25139 run_lenet_gray.cc:160] hbDNNGetModelHandle success
    I0108 07:23:35.508070 25139 run_lenet_gray.cc:176] prepare y tensor success
    I0108 07:23:35.508178 25139 run_lenet_gray.cc:189] prepare tensor success
    I0108 07:23:35.509909 25139 run_lenet_gray.cc:200] infer success
    I0108 07:23:35.510721 25139 run_lenet_gray.cc:205] task done
    I0108 07:23:35.510790 25139 run_lenet_gray.cc:210] task post process finished
    I0108 07:23:35.510832 25139 run_lenet_gray.cc:217] TOP 0 result id: 7
    I0108 07:23:35.510857 25139 run_lenet_gray.cc:217] TOP 1 result id: 9
    I0108 07:23:35.510879 25139 run_lenet_gray.cc:217] TOP 2 result id: 3
    I0108 07:23:35.510903 25139 run_lenet_gray.cc:217] TOP 3 result id: 4
    I0108 07:23:35.510927 25139 run_lenet_gray.cc:217] TOP 4 result id: 2

- The run_resnet50_feature.sh script implements resnet50 model inference using feature input.
  When using it, enter the **03_misc** directory then run ``sh run_resnet50_feature.sh``. 
  The output is shown as below:
  
    .. code-block:: shell
  
      root@j3dvbj3-hynix2G-3200:/userdata/ruxin.song/xj3/script/03_misc# sh run_resnet50_feature.sh
      ../aarch64/bin/run_resnet_feature --model_file=../../model/runtime/resnet50_feature/resnet50_feature_hybrid_horizonrt.bin --data_file=../../data/misc_data/np_0 --top_k=5
      I0000 00:00:00.000000 25155 vlog_is_on.cc:197] RAW: Set VLOG level for "*" to 3
      [HBRT] set log level as 0. version = 3.12.1
      [BPU_PLAT]BPU Platform Version(1.2.2)!
      [HorizonRT] The model builder version = 1.3.3
      I0108 07:25:41.300466 25155 run_resnet_feature.cc:136] hbDNNInitializeFromFiles success
      I0108 07:25:41.300708 25155 run_resnet_feature.cc:144] hbDNNGetModelNameList success
      I0108 07:25:41.300741 25155 run_resnet_feature.cc:151] hbDNNGetModelHandle success
      I0108 07:25:41.302760 25155 run_resnet_feature.cc:166] prepare feature tensor success
      I0108 07:25:41.302919 25155 run_resnet_feature.cc:176] prepare tensor success
      I0108 07:25:41.304678 25155 run_resnet_feature.cc:187] infer success
      I0108 07:25:41.373052 25155 run_resnet_feature.cc:192] task done
      I0108 07:25:41.373328 25155 run_resnet_feature.cc:197] task post process finished
      I0108 07:25:41.373374 25155 run_resnet_feature.cc:204] TOP 0 result id: 74
      I0108 07:25:41.373399 25155 run_resnet_feature.cc:204] TOP 1 result id: 815
      I0108 07:25:41.373422 25155 run_resnet_feature.cc:204] TOP 2 result id: 73
      I0108 07:25:41.373445 25155 run_resnet_feature.cc:204] TOP 3 result id: 78
      I0108 07:25:41.373468 25155 run_resnet_feature.cc:204] TOP 4 result id: 72

Helper Tools and Frequently-used Operations
==============================================

Log
----

There are 2 types of logs: **sample log** and **dnn log**.
Wherein, sample log refers to the log in the BSP release package; 
while dnn log refers to the log in the embedded dnn library.
Developers can specify logs according to their own needs.

Sample Log
~~~~~~~~~~~~~

Sample log uses the VLOG of glog. all logs of basic_samples related samples are dumped.

The ``dnn`` Log
~~~~~~~~~~~~~~~~~~~~

1. Log levels. Logs in the ``dnn`` are composed by 4 levels:

   - When ``HB_DNN_LOG_NONE = 0``, no log will be printed；
   - When ``HB_DNN_LOG_WARNING = 3``, warning information will be printed;
   - When ``HB_DNN_LOG_ERROR = 4``, error information will be printed;
   - When ``HB_DNN_LOG_FATAL = 5``, those errors which can cause quit will be printed.

2. Rules to set log levels:

   If a log event whose level is higher than your specified log level takes place, then it will be printed, otherwise blocked.
   That is to say, the lower level you specify, the more (levels of) logs you are going to get 
   (except for level ``0``, which means print nothing).
   E.g., if you specify log level as ``3`` (i.e. ``WARNING``), then level ``3``, ``4`` and ``5`` logs will be printed.
   The default log level is ``HB_DNN_LOG_WARNING``, i.e., ``WARNING`` , ``ERROR`` and ``FATAL`` logs will be printed.

3. Specify log level. 
   Use the environment variable ``HB_DNN_LOG_LEVEL`` to specify log level. 
   E.g. if ``export HB_DNN_LOG_LEVEL=3``, then all logs whose level are superior to and equal to ``WARNING`` will be printed.

Frequently-used Operations
------------------------------

Check out dev board's image version
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

​Run ``uname -a`` to check system version, the console shall dump below code block:

.. code-block:: shell

  root@j3dvbj3-hynix2G-3200:/userdata/ruxin.song/xj3/script/02_advanced_samples/plugin# uname -a
  Linux j3dvbj3-hynix2G-3200 4.14.74 #8 SMP PREEMPT Wed Mar 3 11:31:24 CST 2021 aarch64 GNU/Linux

.. note::

  - ``SMP`` indicates that the system can support Symmetrical Multi-Processing.
  - ``PREEMPT`` indicates that the system can support preemption core.
  - ``Wed Mar 3 11:31:24 CST 2021`` represents release time of the system image.
  - ``aarch64`` indicates that the aarch64 platform is used.

Check system logs
~~~~~~~~~~~~~~~~~~~~~

Run ``dmesg`` to check system logs, as shown in below code block:

.. code-block:: shell

  root@x3dvbx3-micron1G-3200:/userdata# dmesg
  [    0.000000] Booting Linux on physical CPU 0x0
  [    0.000000] Linux version 4.14.74 (jenkins@sysgbj8) (gcc version 6.5.0 (Linaro GCC 6.5-2018.12)) #2 SMP PREEMPT Fri Oct 23 10:47:39 CST 2020
  [    0.000000] Boot CPU: AArch64 Processor [410fd034]
  [    0.000000] Machine model: Hobot X3 SOC MP DVB
  [    0.000000] earlycon: hobot0 at MMIO 0x00000000a5000000 (options '')
  [    0.000000] bootconsole [hobot0] enabled
  ...

If system failure (e.g. the program is killed or mem allocation failed) takes place when 
running programs in dev board, run ``dmesg`` to see the cause of system failure.

Check BPU Utilization
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Run ``hrut_somstatus`` to check existing BPU utilization of dev board. The output are shown in below code block:

.. code-block:: shell

  =====================1=====================
  temperature-->
    BOARD    : 31.5 (C)
    CPU      : 33.7 (C)
  cpu frequency-->
          min	    cur	    max
    cpu0: 240000	1200000	1200000
    cpu1: 240000	1200000	1200000
    cpu2: 240000	1200000	1200000
    cpu3: 240000	1200000	1200000
  bpu status information---->
          min	      cur       max       ratio
    bpu0: 400000000	1000000000	1000000000	0      // utilization rate of BPU core 0
    bpu1: 400000000	1000000000	1000000000	0      // utilization rate of BPU core 1
  root@x3dvbx3-micron1G-3200:~#
